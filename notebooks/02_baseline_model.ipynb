{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d01ad22-ced1-4ad9-8aec-bd921eaec018",
   "metadata": {},
   "source": [
    "# Fraud Detection & Monitoring (PaySim)\n",
    "\n",
    "**Goal:** Build a baseline fraud detection model and choose an alert threshold that fits a realistic review capacity.\n",
    "\n",
    "**Dataset:** PaySim synthetic mobile money transactions. Target variable: `isFraud`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87e7333-8167-4a42-95a7-ea75038c8b49",
   "metadata": {},
   "source": [
    "## Data scope\n",
    "\n",
    "Fraud in PaySim is concentrated in specific transaction types.  \n",
    "To build a strong baseline and reduce noise, we focus on `TRANSFER` and `CASH_OUT` (the main fraud-driving types) in this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c6c484-2345-4d82-8f34-2765dc640a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_fscore_support\n",
    "\n",
    "DATA_PATH = \"../data/paysim.csv\"\n",
    "FOCUS_TYPES = [\"TRANSFER\", \"CASH_OUT\"]\n",
    "TARGET = \"isFraud\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df = df[df[\"type\"].isin(FOCUS_TYPES)].copy()\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Fraud rate:\", df[TARGET].mean(), f\"({df[TARGET].mean()*100:.4f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de9ff21-86fe-487c-97dc-cf41c53d773e",
   "metadata": {},
   "source": [
    "## Train/test split (time-based)\n",
    "\n",
    "To mimic a real production setup, we split by time (`step`): train on earlier transactions and evaluate on later ones.  \n",
    "This avoids leakage that can happen with random splits in temporal data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99069781-85b0-4e58-84b7-a545cbe56786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by time (step) and split chronologically (80% train / 20% test)\n",
    "df = df.sort_values(\"step\").reset_index(drop=True)\n",
    "\n",
    "split_step = int(df[\"step\"].quantile(0.80))\n",
    "\n",
    "train = df[df[\"step\"] <= split_step].copy()\n",
    "test  = df[df[\"step\"] >  split_step].copy()\n",
    "\n",
    "print(\"Split step:\", split_step)\n",
    "print(f\"Train: {train.shape} | Fraud rate: {train[TARGET].mean():.6f}\")\n",
    "print(f\"Test : {test.shape} | Fraud rate: {test[TARGET].mean():.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b41da6-a0e5-4656-9c97-813637246b07",
   "metadata": {},
   "source": [
    "Note: Fraud prevalence increases in the later period, making the evaluation more realistic and more challenging.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb4cb11-8b4a-4fd5-9ccb-d9c4927e2606",
   "metadata": {},
   "source": [
    "## Baseline model (Logistic Regression)\n",
    "\n",
    "We build a simple, interpretable baseline using Logistic Regression.  \n",
    "Categorical feature `type` is one-hot encoded, numeric features are passed through.  \n",
    "Because fraud is rare, we use `class_weight=\"balanced\"` and evaluate with **ROC-AUC** and **PR-AUC** (more informative under class imbalance).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369de42e-d9b2-4e98-970f-0567eab49e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features / target\n",
    "feature_cols = [\n",
    "    \"type\", \"amount\",\n",
    "    \"oldbalanceOrg\", \"newbalanceOrig\",\n",
    "    \"oldbalanceDest\", \"newbalanceDest\"\n",
    "]\n",
    "\n",
    "X_train = train[feature_cols]\n",
    "y_train = train[TARGET]\n",
    "\n",
    "X_test  = test[feature_cols]\n",
    "y_test  = test[TARGET]\n",
    "\n",
    "# Preprocess: one-hot for categorical, passthrough for numeric\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"type\"]),\n",
    "        (\"num\", \"passthrough\", [\"amount\", \"oldbalanceOrg\", \"newbalanceOrig\", \"oldbalanceDest\", \"newbalanceDest\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    (\"prep\", preprocess),\n",
    "    (\"clf\", LogisticRegression(max_iter=300, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "proba = model.predict_proba(X_test)[:, 1]\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, proba):.4f}\")\n",
    "print(f\"PR-AUC : {average_precision_score(y_test, proba):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634a6eb9-a6e2-43f0-8e77-bc87cb918119",
   "metadata": {},
   "source": [
    "## Threshold tuning (alert volume vs. quality)\n",
    "\n",
    "In practice, fraud models are used to generate **alerts** for manual review.  \n",
    "A lower threshold increases **recall** (catch more fraud) but also creates many more alerts (lower **precision**).\n",
    "\n",
    "Below we evaluate a few thresholds and report:\n",
    "- **precision**: % of alerts that are truly fraud\n",
    "- **recall**: % of fraud we catch\n",
    "- **F1**: balance of precision/recall\n",
    "- **alerts_predicted**: how many cases would be sent to review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77761c2-ac42-4f0b-b8b3-1064f926e978",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.50, 0.30, 0.20, 0.10, 0.05]\n",
    "rows = []\n",
    "\n",
    "for t in thresholds:\n",
    "    pred = (proba >= t).astype(int)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(\n",
    "        y_test, pred, average=\"binary\", zero_division=0\n",
    "    )\n",
    "    rows.append((t, p, r, f1, int(pred.sum())))\n",
    "\n",
    "result = pd.DataFrame(rows, columns=[\"threshold\", \"precision\", \"recall\", \"f1\", \"alerts_predicted\"])\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3399b395-ec72-4fcf-b9b6-b664bcf0cc33",
   "metadata": {},
   "source": [
    "## Monitoring (test period): Model score over time\n",
    "\n",
    "We track the model’s **average fraud score** over time on the **future (test) period**.  \n",
    "A rolling mean is used to reduce noise and reveal trend changes that could indicate **data drift** or behavior shifts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe48bd5e-41de-41c4-9251-e352b0da8373",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Monitoring view on the test period: score + alert volume over time\n",
    "\n",
    "monitor = test.copy()\n",
    "monitor[\"score\"] = proba\n",
    "\n",
    "by_step = monitor.groupby(\"step\").agg(\n",
    "    avg_score=(\"score\", \"mean\"),\n",
    "    tx_count=(\"score\", \"size\")\n",
    ").reset_index()\n",
    "\n",
    "# Smooth trend (rolling window)\n",
    "window = 24\n",
    "by_step[\"avg_score_roll\"] = by_step[\"avg_score\"].rolling(window, min_periods=1).mean()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(by_step[\"step\"], by_step[\"avg_score_roll\"])\n",
    "plt.title(f\"Monitoring: Average model score over time (rolling {window})\")\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"avg score (rolling)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../reports/figures/monitor_avg_score_roll.png\", dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bbcc8d-d3da-43f3-9611-42e11b5d5733",
   "metadata": {},
   "source": [
    "### Key takeaway\n",
    "\n",
    "The average fraud score fluctuates across time steps, so the model remains sensitive to changing transaction patterns in the test period.  \n",
    "If we see a sustained upward/downward shift in this curve in production, it can be an early signal of **data drift** and should trigger model/threshold review.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6833a3-4380-461d-8ccb-22dfd2f7e6d5",
   "metadata": {},
   "source": [
    "## Alert policy: Review-capacity based threshold + alert volume\n",
    "\n",
    "In production, fraud teams review only a limited number of cases.  \n",
    "We simulate this by flagging the **top 1% highest scores** as alerts (quantile-based threshold) and monitor the **alert volume over time**.  \n",
    "This connects model output to a realistic operational constraint (**review capacity**).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841a5d9c-d150-4e05-a3b2-0850be72d887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alert policy: top 1% scores become alerts + alert volume monitoring\n",
    "\n",
    "q = 0.99\n",
    "threshold = float(pd.Series(proba).quantile(q))\n",
    "monitor = test.copy()\n",
    "monitor[\"score\"] = proba\n",
    "monitor[\"alert\"] = (monitor[\"score\"] >= threshold).astype(int)\n",
    "\n",
    "by_step = monitor.groupby(\"step\").agg(\n",
    "    alerts=(\"alert\", \"sum\")\n",
    ").reset_index()\n",
    "\n",
    "window = 24\n",
    "by_step[\"alerts_roll\"] = by_step[\"alerts\"].rolling(window, min_periods=1).mean()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(by_step[\"step\"], by_step[\"alerts_roll\"])\n",
    "plt.title(f\"Monitoring: Alert volume over time (top {(1-q)*100:.0f}% policy, rolling {window})\")\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"alerts per step (rolling)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../reports/figures/monitor_alerts_roll.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Alert threshold (q={q}): {threshold:.6f}\")\n",
    "print(f\"Total alerts in test: {int(monitor['alert'].sum())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2461f5e6-ed04-43d7-aed3-cbf8f65c805c",
   "metadata": {},
   "source": [
    "**Key takeaway**\n",
    "- A fixed “top 1%” alert policy keeps review workload predictable, but alert volume still changes over time.\n",
    "- Spikes indicate periods where customer behavior or transaction mix shifts (potential drift).\n",
    "- In production, this plot helps adjust thresholds or routing rules to keep the review queue stable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca67097-5311-4295-bb41-f2093f949849",
   "metadata": {},
   "outputs": [],
   "source": [
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3856a8-0d31-426e-98d7-76b714326da4",
   "metadata": {},
   "source": [
    "### Key takeaway\n",
    "\n",
    "Lower thresholds produce extremely high recall but overwhelm operations with too many alerts.  \n",
    "This table makes the trade-off explicit: we choose a threshold based on **review capacity**, not just “best” metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d1ef17-a761-4f5b-b0b2-41040c8e20a3",
   "metadata": {},
   "source": [
    "## Threshold sweep: precision/recall vs. alert volume\n",
    "\n",
    "We evaluate several probability thresholds to make the operational trade-off explicit:\n",
    "higher thresholds reduce alert volume (review workload) but may miss more fraud (lower recall).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a6a06a-f630-4ac5-8ecf-037a9df6c485",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.99, 0.97, 0.95, 0.93, 0.90, 0.85, 0.80]\n",
    "rows = []\n",
    "\n",
    "for t in thresholds:\n",
    "    pred = (proba >= t).astype(int)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_test, pred, average=\"binary\", zero_division=0)\n",
    "    rows.append((t, p, r, f1, int(pred.sum())))\n",
    "\n",
    "result = pd.DataFrame(rows, columns=[\"threshold\", \"precision\", \"recall\", \"f1\", \"alerts_predicted\"])\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f1ac77-0f91-4af6-8e3a-b5e08d7bd015",
   "metadata": {},
   "source": [
    "**Interpretation:** This table is used to select a threshold based on realistic review capacity, not just on model metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2c3bfe-13b2-4319-8677-59af72567732",
   "metadata": {},
   "source": [
    "## Alert policy: Top 1% scores as alerts (capacity-based threshold)\n",
    "\n",
    "In practice, fraud teams can only review a limited number of cases per day.  \n",
    "We simulate this by flagging the top 1% highest-risk transactions in the test period as alerts and report the resulting precision/recall and alert volume.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f99f1a2-0122-4ed7-b3c3-6a8cdb5a60ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 0.99  # top 1% as alerts (capacity policy)\n",
    "\n",
    "t = float(pd.Series(proba).quantile(q))\n",
    "pred = (proba >= t).astype(int)\n",
    "\n",
    "p, r, f1, _ = precision_recall_fscore_support(y_test, pred, average=\"binary\", zero_division=0)\n",
    "\n",
    "print(f\"Policy: top {(1-q)*100:.0f}% as alerts (q={q})\")\n",
    "print(f\"Chosen threshold (quantile): {t:.6f}\")\n",
    "print(f\"Alerts predicted: {int(pred.sum())}\")\n",
    "print(f\"Precision: {p:.3f} | Recall: {r:.3f} | F1: {f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08412f6a-55d9-4466-9921-3a030ff7f804",
   "metadata": {},
   "source": [
    "**Key takeaway:** This converts model scores into an operational decision rule.  \n",
    "We choose the threshold based on review capacity, then measure how much fraud we catch (recall) and how many alerts are true fraud (precision).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe3e2a0-802e-41d3-9670-1576ed7739ad",
   "metadata": {},
   "source": [
    "## Operating point (capacity-based)\n",
    "\n",
    "We pick an operating point based on review capacity: flag the **top 1%** highest-risk transactions as alerts, then report precision/recall/F1 and alert volume.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812ff913-474e-4e61-a8dc-73b15d0c09fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operating point: review capacity = top 1% highest-risk transactions\n",
    "q = 0.99\n",
    "threshold = float(pd.Series(proba).quantile(q))\n",
    "pred = (proba >= threshold).astype(int)\n",
    "\n",
    "p, r, f1, _ = precision_recall_fscore_support(\n",
    "    y_test, pred, average=\"binary\", zero_division=0\n",
    ")\n",
    "\n",
    "alerts = int(pred.sum())\n",
    "\n",
    "print(f\"Operating point: top {(1-q)*100:.0f}% alerts (q={q})\")\n",
    "print(f\"Threshold: {threshold:.6f}\")\n",
    "print(f\"Alerts predicted: {alerts}\")\n",
    "print(f\"Precision: {p:.3f} | Recall: {r:.3f} | F1: {f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9041895-fdf4-42bf-a637-967a325e9a4f",
   "metadata": {},
   "source": [
    "## Monitoring: alert rate over time (test period)\n",
    "\n",
    "We monitor how often transactions are flagged as alerts over time (test period).  \n",
    "A rolling mean smooths noise and helps spot regime changes / potential drift.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77bba70-5b20-47d0-b4d3-3d9761282354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitoring: alert rate over time (test period) at the chosen operating threshold\n",
    "monitor = test.copy()\n",
    "monitor[\"score\"] = proba\n",
    "monitor[\"alert\"] = (monitor[\"score\"] >= threshold).astype(int)\n",
    "\n",
    "by_step = (\n",
    "    monitor.groupby(\"step\")[\"alert\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"alert_rate\")\n",
    ")\n",
    "\n",
    "# Smooth with a rolling window (e.g., 24 steps)\n",
    "window = 24\n",
    "by_step[\"alert_rate_roll\"] = by_step[\"alert_rate\"].rolling(window, min_periods=1).mean()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(by_step[\"step\"], by_step[\"alert_rate_roll\"])\n",
    "plt.title(f\"Alert rate over time (rolling {window}) — operating point: top 1%\")\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"alert rate (rolling)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../reports/figures/monitor_alert_rate_roll.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total alerts in test: {int(monitor['alert'].sum())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ab0120-4913-499d-bca4-d32ab793f7e3",
   "metadata": {},
   "source": [
    "## Summary (key outputs)\n",
    "\n",
    "**Goal:** Build a baseline fraud detection model and choose an alert threshold aligned with realistic review capacity.\n",
    "\n",
    "### What we did\n",
    "- **Time-based split** using `step` to mimic production (train on past, test on future)\n",
    "- Focused on high-risk transaction types: **TRANSFER** and **CASH_OUT**\n",
    "- Trained a **Logistic Regression** baseline with `class_weight=\"balanced\"`\n",
    "\n",
    "### Model performance (test set)\n",
    "- **ROC-AUC:** ~0.98  \n",
    "- **PR-AUC:** ~0.72  *(more informative under class imbalance)*\n",
    "\n",
    "### Operating point (review-capacity driven)\n",
    "- Selected **top 1% scores** as alerts (threshold ~0.92)\n",
    "- **Precision:** ~0.54  \n",
    "- **Recall:** ~0.70  \n",
    "- **Total alerts in test:** 5,526\n",
    "\n",
    "### Monitoring view\n",
    "- Produced a **rolling alert-rate over time** plot to support drift monitoring during the test period.\n",
    "\n",
    "### Notes / next steps\n",
    "- Add feature engineering and stronger models (e.g., tree-based)\n",
    "- Calibrate probabilities and evaluate cost-aware thresholds\n",
    "- Add backtesting + simple alert-volume dashboards for operations\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
